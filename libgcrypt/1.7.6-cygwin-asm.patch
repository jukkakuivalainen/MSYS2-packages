Disabled cast5 and rijndael ASM due to linkage errors:

../cipher/.libs/libcipher.a(cast5-amd64.o):cast5-amd64.S:201:(.text+0x9):
relocation truncated to fit: R_X86_64_32S against symbol `_gcry_cast5_s1to4'
defined in .rdata section in ../cipher/.libs/libcipher.a(cast5.o)
../cipher/.libs/libcipher.a(cast5-amd64.o):cast5-amd64.S:241:(.text+0x429):
relocation truncated to fit: R_X86_64_32S against symbol `_gcry_cast5_s1to4'
defined in .rdata section in ../cipher/.libs/libcipher.a(cast5.o)
../cipher/.libs/libcipher.a(cast5-amd64.o):cast5-amd64.S:376:(.text+0x844):
relocation truncated to fit: R_X86_64_32S against symbol `_gcry_cast5_s1to4'
defined in .rdata section in ../cipher/.libs/libcipher.a(cast5.o)
../cipher/.libs/libcipher.a(cast5-amd64.o):cast5-amd64.S:404:(.text+0x177c):
relocation truncated to fit: R_X86_64_32S against symbol `_gcry_cast5_s1to4'
defined in .rdata section in ../cipher/.libs/libcipher.a(cast5.o)
rijndael.c:747:(.text+0x9f): relocation truncated to fit: R_X86_64_32S
against `.rdata'
rijndael.c:1130:(.text+0x110): relocation truncated to fit: R_X86_64_32S
against `.rdata'

--- origsrc/libgcrypt-1.7.6/acinclude.m4	2016-12-15 02:14:20.000000000 -0600
+++ src/libgcrypt-1.7.6/acinclude.m4	2017-05-09 23:41:57.191299500 -0500
@@ -101,10 +101,10 @@ AC_DEFUN([GNUPG_CHECK_GNUMAKE],
 AC_DEFUN([GNUPG_SYS_SYMBOL_UNDERSCORE],
 [tmp_do_check="no"
 case "${host}" in
-    i?86-mingw32* | i?86-*-mingw32*)
+    i?86-mingw32* | i?86-*-mingw32* | i?86-*-cygwin*)
         ac_cv_sys_symbol_underscore=yes
         ;;
-    x86_64-*-mingw32*)
+    x86_64-*-mingw32* | x86_64-*-cygwin*)
         ac_cv_sys_symbol_underscore=no
         ;;
     i386-emx-os2 | i[3456]86-pc-os2*emx | i386-pc-msdosdjgpp)
--- origsrc/libgcrypt-1.7.6/cipher/cast5-amd64.S	2016-03-23 06:59:34.000000000 -0500
+++ src/libgcrypt-1.7.6/cipher/cast5-amd64.S	2017-05-10 16:25:42.251955500 -0500
@@ -21,7 +21,7 @@
 #ifdef __x86_64
 #include <config.h>
 #if (defined(HAVE_COMPATIBLE_GCC_AMD64_PLATFORM_AS) || \
-     defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS)) && defined(USE_CAST5)
+     defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS)) && defined(USE_CAST5) && !defined(__CYGWIN__)
 
 #if defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS) || !defined(__PIC__)
 #  define GET_EXTERN_POINTER(name, reg) leaq name, reg
--- origsrc/libgcrypt-1.7.6/cipher/cast5.c	2016-03-23 06:59:34.000000000 -0500
+++ src/libgcrypt-1.7.6/cipher/cast5.c	2017-05-10 16:25:09.928907300 -0500
@@ -49,7 +49,7 @@
 /* USE_AMD64_ASM indicates whether to use AMD64 assembly code. */
 #undef USE_AMD64_ASM
 #if defined(__x86_64__) && (defined(HAVE_COMPATIBLE_GCC_AMD64_PLATFORM_AS) || \
-    defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS))
+    defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS)) && !defined(__CYGWIN__)
 # define USE_AMD64_ASM 1
 #endif
 
--- origsrc/libgcrypt-1.7.6/cipher/cipher-gcm-intel-pclmul.c	2016-03-23 06:59:34.000000000 -0500
+++ src/libgcrypt-1.7.6/cipher/cipher-gcm-intel-pclmul.c	2017-05-10 11:53:45.020966600 -0500
@@ -249,7 +249,7 @@ void
 _gcry_ghash_setup_intel_pclmul (gcry_cipher_hd_t c)
 {
   u64 tmp[2];
-#if defined(__x86_64__) && defined(__WIN64__)
+#if HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   char win64tmp[3 * 16];
 
   /* XMM6-XMM8 need to be restored after use. */
@@ -296,7 +296,7 @@ _gcry_ghash_setup_intel_pclmul (gcry_cip
                 : [h_234] "r" (c->u_mode.gcm.gcm_table)
                 : "memory");
 
-#ifdef __WIN64__
+#ifdef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   /* Clear/restore used registers. */
   asm volatile( "pxor %%xmm0, %%xmm0\n\t"
                 "pxor %%xmm1, %%xmm1\n\t"
@@ -336,14 +336,14 @@ _gcry_ghash_intel_pclmul (gcry_cipher_hd
   static const unsigned char be_mask[16] __attribute__ ((aligned (16))) =
     { 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0 };
   const unsigned int blocksize = GCRY_GCM_BLOCK_LEN;
-#ifdef __WIN64__
+#ifdef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   char win64tmp[10 * 16];
 #endif
 
   if (nblocks == 0)
     return 0;
 
-#ifdef __WIN64__
+#ifdef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   /* XMM8-XMM15 need to be restored after use. */
   asm volatile ("movdqu %%xmm6,  0*16(%0)\n\t"
                 "movdqu %%xmm7,  1*16(%0)\n\t"
@@ -400,7 +400,7 @@ _gcry_ghash_intel_pclmul (gcry_cipher_hd
         }
       while (nblocks >= 4);
 
-#ifndef __WIN64__
+#ifndef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
       /* Clear used x86-64/XMM registers. */
       asm volatile( "pxor %%xmm8, %%xmm8\n\t"
                     "pxor %%xmm9, %%xmm9\n\t"
@@ -434,7 +434,7 @@ _gcry_ghash_intel_pclmul (gcry_cipher_hd
                 : [hash] "=m" (*result)
                 : [be_mask] "m" (*be_mask));
 
-#ifdef __WIN64__
+#ifdef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   /* Clear/restore used registers. */
   asm volatile( "pxor %%xmm0, %%xmm0\n\t"
                 "pxor %%xmm1, %%xmm1\n\t"
--- origsrc/libgcrypt-1.7.6/cipher/crc-intel-pclmul.c	2016-08-19 03:27:55.000000000 -0500
+++ src/libgcrypt-1.7.6/cipher/crc-intel-pclmul.c	2017-05-10 11:52:31.662601800 -0500
@@ -852,7 +852,7 @@ void
 _gcry_crc32_intel_pclmul (u32 *pcrc, const byte *inbuf, size_t inlen)
 {
   const struct crc32_consts_s *consts = &crc32_consts;
-#if defined(__x86_64__) && defined(__WIN64__)
+#if HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   char win64tmp[2 * 16];
 
   /* XMM6-XMM7 need to be restored after use. */
@@ -871,7 +871,7 @@ _gcry_crc32_intel_pclmul (u32 *pcrc, con
   else
     crc32_reflected_less_than_16(pcrc, inbuf, inlen, consts);
 
-#if defined(__x86_64__) && defined(__WIN64__)
+#if HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   /* Restore used registers. */
   asm volatile("movdqu 0*16(%0), %%xmm6\n\t"
                "movdqu 1*16(%0), %%xmm7\n\t"
@@ -885,7 +885,7 @@ void
 _gcry_crc24rfc2440_intel_pclmul (u32 *pcrc, const byte *inbuf, size_t inlen)
 {
   const struct crc32_consts_s *consts = &crc24rfc2440_consts;
-#if defined(__x86_64__) && defined(__WIN64__)
+#if HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   char win64tmp[2 * 16];
 
   /* XMM6-XMM7 need to be restored after use. */
@@ -906,7 +906,7 @@ _gcry_crc24rfc2440_intel_pclmul (u32 *pc
   else
     crc32_less_than_16(pcrc, inbuf, inlen, consts);
 
-#if defined(__x86_64__) && defined(__WIN64__)
+#if HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
   /* Restore used registers. */
   asm volatile("movdqu 0*16(%0), %%xmm6\n\t"
                "movdqu 1*16(%0), %%xmm7\n\t"
--- origsrc/libgcrypt-1.7.6/cipher/rijndael-aesni.c	2017-01-18 05:28:40.000000000 -0600
+++ src/libgcrypt-1.7.6/cipher/rijndael-aesni.c	2017-05-10 11:48:41.796326200 -0500
@@ -49,7 +49,7 @@ typedef struct u128_s { u32 a, b, c, d;
    the use of these macros.  There purpose is to make sure that the
    SSE regsiters are cleared and won't reveal any information about
    the key or the data.  */
-#ifdef __WIN64__
+#ifdef HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS
 /* XMM6-XMM15 are callee-saved registers on WIN64. */
 # define aesni_prepare_2_6_variable char win64tmp[16]
 # define aesni_prepare() do { } while (0)
--- origsrc/libgcrypt-1.7.6/cipher/rijndael-internal.h	2016-11-12 04:39:35.000000000 -0600
+++ src/libgcrypt-1.7.6/cipher/rijndael-internal.h	2017-05-10 16:26:21.160824000 -0500
@@ -40,7 +40,7 @@
 /* USE_AMD64_ASM indicates whether to use AMD64 assembly code. */
 #undef USE_AMD64_ASM
 #if defined(__x86_64__) && (defined(HAVE_COMPATIBLE_GCC_AMD64_PLATFORM_AS) || \
-    defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS))
+    defined(HAVE_COMPATIBLE_GCC_WIN64_PLATFORM_AS)) && !defined(__CYGWIN__)
 # define USE_AMD64_ASM 1
 #endif
 
